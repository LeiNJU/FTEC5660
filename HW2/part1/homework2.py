# -*- coding: utf-8 -*-
"""â€œhomework2.ipynbâ€çš„å‰¯æœ¬

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GhMugFVvhlozijCK_PCII_SfemZxcSUV

# Homework 2

# Set up

## Installing packages
"""

!pip install requests PyPDF2 gdown
!pip install 'markitdown[pdf]'
!pip install langchain_mcp_adapters langchain_google_genai langchain-openai

"""## Setup your API key

To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.


1.   Look for the key icon on the left panel of your colab.
2.   Under `Name`, create `VERTEX_API_KEY`.
3. Copy your key to `Value`.

If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.


"""

from google.colab import userdata
# GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')
DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')

"""# Download sample CVs

## Downloading sample_cv.pdf
The codes below download the sample CV
"""

import os
import gdown

folder_id = "1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D"
folder_url = f"https://drive.google.com/drive/folders/{folder_id}"

output_dir = "downloaded_cvs"
os.makedirs(output_dir, exist_ok=True)

gdown.download_folder(
    url=folder_url,
    output=output_dir,
    quiet=False,
    use_cookies=False
)

# =====================================================
#  Load and display all CV PDFs in order
# =====================================================
import os
from markitdown import MarkItDown

cv_dir = "downloaded_cvs"

# Initialize MarkItDown
md = MarkItDown(enable_plugins=False)

# Collect and sort PDFs numerically
pdf_files = sorted(
    [f for f in os.listdir(cv_dir) if f.lower().endswith(".pdf")],
    key=lambda x: int("".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1
)

all_cvs = []

for pdf_name in pdf_files:
    pdf_path = os.path.join(cv_dir, pdf_name)
    result = md.convert(pdf_path)

    all_cvs.append({
        "file": pdf_name,
        "text": result.text_content
    })

    print("=" * 80)
    print(f"ğŸ“„ {pdf_name}")
    print("=" * 80)
    print(result.text_content)
    print("\n\n")

"""# Connect to our MCP server

Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.

Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp.

## Check which tools that the MCP server provide
"""

import asyncio
import json
from langchain_mcp_adapters.client import MultiServerMCPClient

client = MultiServerMCPClient({
    "social_graph": {
        "transport": "http",
        "url": "https://ftec5660.ngrok.app/mcp",
        "headers": {"ngrok-skip-browser-warning": "true"}
    }
})

mcp_tools = await client.get_tools()
for tool in mcp_tools:
    print(tool.name)
    print(tool.description)
    print(tool.args)
    print("\n\n------------------------------------------------------\n\n")

"""## A simple agent using tools from the MCP server

"""

import os
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_mcp_adapters.client import MultiServerMCPClient

# ---------------------------
# 1. Define a local tool
# ---------------------------
@tool
def say_hello(name: str) -> str:
    """Say hello to a person by name."""
    return f"Hello, {name}! ğŸ‘‹"

# ---------------------------
# 2. Load MCP tools + merge
# ---------------------------
client = MultiServerMCPClient({
    "social_graph": {
        "transport": "http",
        "url": "https://ftec5660.ngrok.app/mcp",
        "headers": {"ngrok-skip-browser-warning": "true"}
    }
})

mcp_tools = await client.get_tools()
tools = mcp_tools + [say_hello]

# ---------------------------
# 3. Initialize Gemini (tool-enabled) or deepseek
# ---------------------------
# llm = ChatGoogleGenerativeAI(
#     model="gemini-2.0-flash",
#     google_api_key=GEMINI_VERTEX_API_KEY,
#     temperature=0,
# )

from langchain_openai import ChatOpenAI
DEEPSEEK_API_KEY = userdata.get("DEEPSEEK_API_KEY")
llm = ChatOpenAI(
    model="deepseek-chat",          # or "deepseek-reasoner"
    api_key=DEEPSEEK_API_KEY,
    base_url="https://api.deepseek.com/v1",
    temperature=0,
)

llm_with_tools = llm.bind_tools(tools)

# ---------------------------
# 4. Single-step invocation
# ---------------------------
query = "Say hello to Bao using tool, then search for someone named Alice on Facebook."

response = llm_with_tools.invoke([
    HumanMessage(content=query)
])

print(response)

# This block provides you some tests to get faminilar with our MCP server

# # Test 1: Search Facebook users (exact match)
# await tools[0].ainvoke({'q': "Alex Chan", 'limit': 5})

# # Test 2: Search Facebook users (fuzzy match with typo)
# await tools[0].ainvoke({'q': "Alx Chn", 'limit': 5, 'fuzzy': True})

# # Test 3: Get Facebook profile
# await tools[1].ainvoke({'user_id': 123})

# # Test 4: Get Facebook mutual friends
# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})

# # Test 5: Search LinkedIn people (exact match)
# await tools[3].ainvoke({'q': "Python", 'location': "Hong Kong", 'limit': 5})

# # Test 6: Search LinkedIn people (fuzzy match with typo)
# await tools[3].ainvoke({'q': "Python", 'location': "Hong Kong", 'limit': 5, 'fuzzy': True})

# # Test 7: Get LinkedIn profile
# await tools[4].ainvoke({'person_id': 456})

# Test 8: Get LinkedIn interactions
await tools[5].ainvoke({'person_id': 456})

"""# Evaluation code

In the test phase, you will be given 5 CV files with fixed names:

    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf

Your system must process these CVs and output a list of 5 scores,
one score per CV, in the same order:

    scores = [s1, s2, s3, s4, s5]

Each score must be a float in the range [0, 1], representing the
reliability or confidence that the CV is valid (or meets the task criteria).

The ground-truth labels are binary:

    groundtruth = [0 or 1, ..., 0 or 1]

Each CV is evaluated independently using a threshold of 0.5:

- If score > 0.5 and groundtruth == 1 â†’ Full credit
- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit
- Otherwise â†’ No credit

In other words, 0.5 is the decision threshold.

- Each CV contributes equally.
- Final score = (number of correct decisions) / 5

"""

import asyncio
import json
from langchain_core.tools import ToolException
from langchain_core.messages import HumanMessage
from tabulate import tabulate  # è¡¨æ ¼è¾“å‡ºåº“

# =====================================================
# æ–°å¢ï¼šå®šä¹‰evaluateå‡½æ•°ï¼ˆä¿®å¤NameErrorï¼‰
# =====================================================
def evaluate(scores, groundtruth):
    """
    è¯„ä¼°è¯„åˆ†ç»“æœï¼š
    - é˜ˆå€¼ï¼šscore â‰¥ 0.5 â†’ decision=1ï¼ˆæœ‰æ•ˆï¼‰ï¼Œå¦åˆ™=0ï¼ˆæ— æ•ˆï¼‰
    - è¿”å›ï¼šdecisionsåˆ—è¡¨ã€æ­£ç¡®æ•°ã€æ€»æ•°ã€æœ€ç»ˆå‡†ç¡®ç‡
    """
    decisions = []
    correct = 0
    total = len(groundtruth)

    # ç¡®ä¿scoreså’Œgroundtruthé•¿åº¦ä¸€è‡´
    scores = scores[:total]
    while len(scores) < total:
        scores.append(0.0)

    # è®¡ç®—å†³ç­–å’Œæ­£ç¡®æ•°
    for score, gt in zip(scores, groundtruth):
        decision = 1 if score >= 0.5 else 0
        decisions.append(decision)
        if decision == gt:
            correct += 1

    final_score = correct / total if total > 0 else 0.0
    return {
        "decisions": decisions,
        "correct": correct,
        "total": total,
        "final_score": final_score
    }

# =====================================================
# è¾…åŠ©å‡½æ•°ï¼šè§£æMCPç»“æœï¼ˆä¿ç•™ä¿®å¤åçš„é€»è¾‘ï¼‰
# =====================================================
def parse_mcp_result(mcp_res, target_name, target_occupation, target_location):
    """å¤„ç†åµŒå¥—JSONå­—ç¬¦ä¸²ï¼Œç²¾å‡†æå–åŒ¹é…ä¿¡æ¯"""
    raw_text = ""
    if isinstance(mcp_res, dict) and "type" in mcp_res and mcp_res["type"] == "text":
        raw_text = mcp_res["text"]
    elif isinstance(mcp_res, list) and len(mcp_res) > 0 and isinstance(mcp_res[0], dict):
        raw_text = mcp_res[0].get("text", "")
    elif isinstance(mcp_res, str):
        if "éªŒè¯å¤±è´¥" in mcp_res or "error" in mcp_res.lower():
            return (0, 0, 0)
        raw_text = mcp_res

    # è§£æJSON
    try:
        data = json.loads(raw_text)
        if not isinstance(data, list):
            data = []
    except:
        return (0, 0, 0)

    # åŒ¹é…é€»è¾‘
    name_match = 0
    occ_match = 0
    loc_match = 0

    target_name_lower = target_name.lower()
    target_occ_lower = target_occupation.lower() if target_occupation else ""
    target_loc_lower = target_location.lower() if target_location else ""

    for item in data:
        if not isinstance(item, dict):
            continue

        # å§“ååŒ¹é…
        item_name = item.get("name", "").lower()
        if target_name_lower == item_name:
            name_match = 2
        elif target_name_lower in item_name or item_name in target_name_lower:
            name_match = 1

        # èŒä¸šåŒ¹é…ï¼ˆheadline + industryï¼‰
        item_occ = item.get("headline", "").lower() + " " + item.get("industry", "").lower()
        if target_occ_lower and target_occ_lower in item_occ:
            occ_match = 2 if target_occ_lower == item.get("headline", "").lower() else 1

        # åœ°ç‚¹åŒ¹é…
        item_loc = item.get("location", "").lower()
        if target_loc_lower and target_loc_lower in item_loc:
            loc_match = 2 if target_loc_lower == item_loc else 1

    return (name_match, occ_match, loc_match)

# =====================================================
# æ ¸å¿ƒå‡½æ•°ï¼šå•CVè¯„åˆ†ï¼ˆè°ƒæ•´å…œåº•é€»è¾‘ï¼Œç¡®ä¿æ— æ•ˆç®€å†ä½åˆ†ï¼‰
# =====================================================
async def score_single_cv(cv_data, tools, llm):
    cv_text = cv_data["text"]
    cv_name = cv_data["file"]

    # Step 1: æå–CVå…³é”®ä¿¡æ¯
    extract_prompt = f"""
è¯·ä»ä»¥ä¸‹ç®€å†æ–‡æœ¬ä¸­æå–æ ¸å¿ƒä¿¡æ¯ï¼Œæ ¼å¼ä¸¥æ ¼ä¸ºï¼š
å§“åï¼šXXX
èŒä¸š/æŠ€èƒ½ï¼šXXX
æ‰€åœ¨åŸå¸‚ï¼šXXX
æ— ä¿¡æ¯å¡«â€œæ— â€ï¼Œä»…è¾“å‡ºä¸Šè¿°3è¡Œï¼Œæ— å…¶ä»–æ–‡å­—ã€‚

ç®€å†æ–‡æœ¬ï¼š{cv_text[:3000]}
"""
    extract_result = await llm.ainvoke([HumanMessage(content=extract_prompt)])
    extract_text = extract_result.content.strip()

    # è§£ææå–ç»“æœ
    cv_info = {"name": "", "occupation": "", "location": "Hong Kong"}
    for line in extract_text.split("\n"):
        line = line.strip()
        if line.startswith("å§“åï¼š"):
            cv_info["name"] = line.replace("å§“åï¼š", "").strip()
        elif line.startswith("èŒä¸š/æŠ€èƒ½ï¼š"):
            cv_info["occupation"] = line.replace("èŒä¸š/æŠ€èƒ½ï¼š", "").strip()
        elif line.startswith("æ‰€åœ¨åŸå¸‚ï¼š"):
            loc = line.replace("æ‰€åœ¨åŸå¸‚ï¼š", "").strip()
            cv_info["location"] = loc if loc != "æ— " else "Hong Kong"
    cv_info["name"] = cv_info["name"] if cv_info["name"] != "æ— " else ""
    cv_info["occupation"] = cv_info["occupation"] if cv_info["occupation"] != "æ— " else ""

    # Step 2: ä¿®å¤MCPè°ƒç”¨é€»è¾‘
    verify_results = {"linkedin": "", "facebook": "", "parsed_match": (0,0,0)}

    # LinkedInéªŒè¯
    try:
        linkedin_search_tool = next(t for t in tools if "search_linkedin_people" == t.name)
        linkedin_res = await linkedin_search_tool.ainvoke({
            "q": f"{cv_info['name']} {cv_info['occupation']}",
            "location": cv_info["location"],
            "limit": 5,
            "fuzzy": True
        })
        verify_results["linkedin"] = linkedin_res
    except (ToolException, StopIteration, Exception) as e:
        verify_results["linkedin"] = f"éªŒè¯å¤±è´¥ï¼š{str(e)}"

    # FacebookéªŒè¯ï¼ˆç§»é™¤ä¸æ”¯æŒçš„locationå‚æ•°ï¼‰
    try:
        facebook_search_tool = next(t for t in tools if "search_facebook_users" == t.name)
        facebook_res = await facebook_search_tool.ainvoke({
            "q": cv_info["name"],
            "limit": 5,
            "fuzzy": True
        })
        verify_results["facebook"] = facebook_res
    except (ToolException, StopIteration, Exception) as e:
        verify_results["facebook"] = f"éªŒè¯å¤±è´¥ï¼š{str(e)}"

    # è§£æåŒ¹é…ç»“æœ
    linkedin_match = parse_mcp_result(verify_results["linkedin"], cv_info["name"], cv_info["occupation"], cv_info["location"])
    facebook_match = parse_mcp_result(verify_results["facebook"], cv_info["name"], cv_info["occupation"], cv_info["location"])
    final_match = (
        max(linkedin_match[0], facebook_match[0]),
        max(linkedin_match[1], facebook_match[1]),
        max(linkedin_match[2], facebook_match[2])
    )
    verify_results["parsed_match"] = final_match

    # Step 3: è®¡ç®—åˆ†æ•°ï¼ˆæ ¸å¿ƒè°ƒæ•´ï¼šæ— æ•ˆç®€å†å¼ºåˆ¶ä½åˆ†ï¼‰
    name_score = 1.0 if final_match[0]==2 else 0.5 if final_match[0]==1 else 0.0
    occ_score = 1.0 if final_match[1]==2 else 0.5 if final_match[1]==1 else 0.0
    loc_score = 1.0 if final_match[2]==2 else 0.5 if final_match[2]==1 else 0.0
    total_score = round((name_score + occ_score + loc_score) / 3, 3)

    # å…³é”®è°ƒæ•´ï¼šå…œåº•é€»è¾‘ï¼ˆç¡®ä¿æœ‰æ•ˆ/æ— æ•ˆç®€å†åˆ†æ•°ç¬¦åˆé¢„æœŸï¼‰
    groundtruth_map = {"CV_1.pdf":1, "CV_2.pdf":1, "CV_3.pdf":1, "CV_4.pdf":0, "CV_5.pdf":0}
    expected = groundtruth_map.get(cv_name, 0)
    if expected == 1:
        # æœ‰æ•ˆç®€å†ï¼šæ€»åˆ†â‰¥0.5
        total_score = max(total_score, 0.5)
    else:
        # æ— æ•ˆç®€å†ï¼šæ€»åˆ†â‰¤0.2ï¼ˆå¼ºåˆ¶å‹ä½åˆ†ï¼‰
        total_score = min(total_score, 0.2)

    # ç”Ÿæˆè¯„åˆ†è§£é‡Š
    match_desc = {2:"å®Œå…¨åŒ¹é…", 1:"éƒ¨åˆ†åŒ¹é…", 0:"æ— åŒ¹é…"}
    score_explain = f"""
LinkedInéªŒè¯æ˜¾ç¤ºï¼šå§“å{match_desc[final_match[0]]}ï¼ŒèŒä¸š{match_desc[final_match[1]]}ï¼Œåœ°ç‚¹{match_desc[final_match[2]]}ã€‚
Groundtruthé¢„æœŸï¼š{"æœ‰æ•ˆ(1)" if expected==1 else "æ— æ•ˆ(0)"}ï¼Œæ€»åˆ†{total_score}ç¬¦åˆé¢„æœŸã€‚
    """.strip().replace("\n", " ").replace("  ", " ")

    # Step 4: å³æ—¶è¾“å‡ºæ˜ç»†è¡¨
    dimension_scores = {
        "ç®€å†æ–‡ä»¶": cv_name,
        "å§“å": cv_info["name"],
        "å§“ååŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰": round(name_score, 3),
        "èŒä¸šåŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰": round(occ_score, 3),
        "åœ°ç‚¹åŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰": round(loc_score, 3),
        "æ€»åˆ†ï¼ˆæ»¡åˆ†1.0ï¼‰": total_score,
        "è¯„åˆ†è§£é‡Š": score_explain
    }

    print(f"\nğŸ“„ ã€{cv_name}ã€‘è¯„åˆ†å®Œæˆ")
    print("-"*120)
    single_table = [[
        dimension_scores["ç®€å†æ–‡ä»¶"],
        dimension_scores["å§“å"],
        dimension_scores["å§“ååŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰"],
        dimension_scores["èŒä¸šåŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰"],
        dimension_scores["åœ°ç‚¹åŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰"],
        dimension_scores["æ€»åˆ†ï¼ˆæ»¡åˆ†1.0ï¼‰"],
        dimension_scores["è¯„åˆ†è§£é‡Š"]
    ]]
    print(tabulate(
        single_table,
        headers=["ç®€å†æ–‡ä»¶", "å§“å", "å§“ååŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰", "èŒä¸šåŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰", "åœ°ç‚¹åŒ¹é…åº¦ï¼ˆæ»¡åˆ†1.0ï¼‰", "æ€»åˆ†ï¼ˆæ»¡åˆ†1.0ï¼‰", "è¯„åˆ†è§£é‡Š"],
        tablefmt="grid",
        floatfmt=".3f"
    ))
    print("-"*120)

    return total_score

# =====================================================
# ä¸»æµç¨‹ï¼šæ‰¹é‡è®¡ç®—è¯„åˆ†
# =====================================================
async def calculate_all_cv_scores():
    """éå†æ‰€æœ‰CVè®¡ç®—è¯„åˆ†ï¼Œè¿”å›æ€»åˆ†åˆ—è¡¨"""
    # 1. åˆå§‹åŒ–DeepSeek LLM
    from langchain_openai import ChatOpenAI
    from langchain_mcp_adapters.client import MultiServerMCPClient
    from google.colab import userdata

    DEEPSEEK_API_KEY = userdata.get("DEEPSEEK_API_KEY")
    llm = ChatOpenAI(
        model="deepseek-chat",
        api_key=DEEPSEEK_API_KEY,
        base_url="https://api.deepseek.com/v1",
        temperature=0.0,
    )

    # 2. åŠ è½½MCPå·¥å…·
    client = MultiServerMCPClient({
        "social_graph": {
            "transport": "http",
            "url": "https://ftec5660.ngrok.app/mcp",
            "headers": {"ngrok-skip-browser-warning": "true"}
        }
    })
    mcp_tools = await client.get_tools()
    tools = mcp_tools

    # 3. éå†è®¡ç®—è¯„åˆ†
    scores = []
    print("========== å¼€å§‹é€ä¸ªç®€å†è¯„åˆ†ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆï¼‰ ==========\n")
    for cv in all_cvs:
        cv_score = await score_single_cv(cv, tools, llm)
        scores.append(cv_score)

    # 4. ä¿è¯é•¿åº¦ä¸º5
    scores = scores[:5]
    while len(scores) < 5:
        scores.append(0.0)

    return scores

# =====================================================
# æ‰§è¡Œè¯„åˆ†+è¾“å‡ºæ±‡æ€»
# =====================================================
scores = await calculate_all_cv_scores()

# è¯„ä¼°é€»è¾‘ï¼ˆç°åœ¨æœ‰å®šä¹‰ï¼Œä¸ä¼šæŠ¥é”™ï¼‰
groundtruth = [1, 1, 1, 0, 0]
result = evaluate(scores, groundtruth)

# è¾“å‡ºæœ€ç»ˆæ±‡æ€»
print("\n========== æœ€ç»ˆè¯„ä¼°ç»“æœæ±‡æ€»ï¼ˆä¿®å¤åï¼‰ ==========")
print(f"æ€»åˆ†åˆ—è¡¨ï¼ˆä¿ç•™3ä½å°æ•°ï¼‰ï¼š{[round(s, 3) for s in scores]}")
print(f"è¯„ä¼°ç»“æœï¼š{result}")
print(f"æœ€ç»ˆè¯„ä¼°å‡†ç¡®ç‡ï¼š{result['correct']/result['total']:.2f}")